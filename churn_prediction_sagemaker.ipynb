{"nbformat": 4, "nbformat_minor": 5, "metadata": {}, "cells": [{"id": "13a36fa9", "cell_type": "markdown", "source": "# Churn Prediction using Amazon SageMaker (XGBoost \u2013 Script Mode)\n\nThis notebook contains only the steps that worked end-to-end.", "metadata": {}}, {"id": "8b29b476", "cell_type": "markdown", "source": "## 1. Load & Clean Dataset", "metadata": {}}, {"id": "4ff74a52", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\nimport pandas as pd\n\ndf = pd.read_excel(\"E Commerce Dataset.xlsx\", sheet_name=\"E Comm\")\ndf = df.dropna()\n\nchurn = df[\"Churn\"]\ndf = df.drop(columns=[\"Churn\"])\ndf[\"Churn\"] = churn\n\ndf.to_csv(\"xgb_train.csv\", header=False, index=False)\nprint(\"Saved cleaned dataset\")\n", "outputs": []}, {"id": "d26ce4ba", "cell_type": "markdown", "source": "## 2. Upload Dataset to S3", "metadata": {}}, {"id": "ba9fdb21", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\nimport boto3\n\nbucket = \"sparkify-churn-mlproject-apse2\"\nkey = \"xgb_train/xgb_train.csv\"\n\ns3 = boto3.client(\"s3\")\ns3.upload_file(\"xgb_train.csv\", bucket, key)\n\nprint(f\"Uploaded to s3://{bucket}/{key}\")\n", "outputs": []}, {"id": "396951b1", "cell_type": "markdown", "source": "## 3. Training Script", "metadata": {}}, {"id": "2239b1f7", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n%%writefile train.py\nimport argparse\nimport pandas as pd\nimport xgboost as xgb\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model_dir\", type=str, default=\"/opt/ml/model\")\n    parser.add_argument(\"--train\", type=str, default=\"/opt/ml/input/data/train\")\n    args = parser.parse_args()\n\n    df = pd.read_csv(f\"{args.train}/xgb_train.csv\", header=None)\n    X = df.iloc[:, :-1]\n    y = df.iloc[:, -1]\n\n    dtrain = xgb.DMatrix(X, label=y)\n    params = {\n        \"objective\": \"binary:logistic\",\n        \"max_depth\": 5,\n        \"eta\": 0.2,\n        \"eval_metric\": \"logloss\"\n    }\n\n    model = xgb.train(params, dtrain, num_boost_round=200)\n    model.save_model(f\"{args.model_dir}/xgboost-model\")\n", "outputs": []}, {"id": "3fdb61ff", "cell_type": "markdown", "source": "## 4. Train on SageMaker", "metadata": {}}, {"id": "0b5f87b9", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\nimport sagemaker\nfrom sagemaker.xgboost.estimator import XGBoost\nfrom sagemaker.inputs import TrainingInput\n\nrole = sagemaker.get_execution_role()\n\nxgb = XGBoost(\n    entry_point=\"train.py\",\n    source_dir=\".\",\n    framework_version=\"1.3-1\",\n    py_version=\"py3\",\n    instance_type=\"ml.m5.large\",\n    role=role,\n)\n\nxgb.fit({\n    \"train\": TrainingInput(\n        f\"s3://{bucket}/{key}\",\n        content_type=\"text/csv\"\n    )\n})\n", "outputs": []}, {"id": "1bf2f49d", "cell_type": "markdown", "source": "## 5. Deploy Endpoint", "metadata": {}}, {"id": "4c41f53b", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\npredictor = xgb.deploy(\n    initial_instance_count=1,\n    instance_type=\"ml.m5.large\"\n)\nprint(predictor.endpoint_name)\n", "outputs": []}, {"id": "d610606a", "cell_type": "markdown", "source": "## 6. Predict", "metadata": {}}, {"id": "a384140c", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\nsample = df.iloc[[0]].drop(columns=[\"Churn\"])\npayload = sample.to_csv(header=False, index=False)\n\nprediction = predictor.predict(payload)\nprint(prediction)\n", "outputs": []}, {"id": "d1068848", "cell_type": "markdown", "source": "## 7. Cleanup", "metadata": {}}, {"id": "67bf1c9d", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\npredictor.delete_endpoint()\nprint(\"Endpoint deleted\")\n", "outputs": []}]}